{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "N75LHkBuv74z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "rZLAbMOAv740"
      },
      "outputs": [],
      "source": [
        "# Adjusting the KNN class to handle NumPy arrays directly without needing the `.values` attribute\n",
        "\n",
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fit the KNN model with training data.\"\"\"\n",
        "        self.X_train = X  # No need to convert to NumPy array\n",
        "        self.y_train = y.astype(int)  # Ensure integer labels\n",
        "\n",
        "    def compute_distance(self, X1, X2):\n",
        "        \"\"\"Compute distance between two points based on the specified distance metric.\"\"\"\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            return np.sqrt(np.sum((X1 - X2) ** 2, axis=1))\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            return np.sum(np.abs(X1 - X2), axis=1)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported distance metric: {self.distance_metric}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict labels for input data.\"\"\"\n",
        "        predictions = []\n",
        "        for i in range(X.shape[0]):\n",
        "            distances = self.compute_distance(self.X_train, X[i, :])\n",
        "            nearest_neighbors = np.argsort(distances)[:self.k]\n",
        "            nearest_labels = self.y_train[nearest_neighbors]\n",
        "            majority_label = np.argmax(np.bincount(nearest_labels))  # Majority voting\n",
        "            predictions.append(majority_label)\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Predict the probability of each class for input data.\"\"\"\n",
        "        probabilities = []\n",
        "        for i in range(X.shape[0]):\n",
        "            distances = self.compute_distance(self.X_train, X[i, :])\n",
        "            nearest_neighbors = np.argsort(distances)[:self.k]\n",
        "            nearest_labels = self.y_train[nearest_neighbors]\n",
        "            prob = np.mean(nearest_labels)  # Probability is the mean of nearest labels\n",
        "            probabilities.append(prob)\n",
        "        return np.array(probabilities)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "O0EzslQIv740"
      },
      "outputs": [],
      "source": [
        "# Implementing a custom standard scaler function to replace StandardScaler from sklearn\n",
        "def custom_standard_scaler(X):\n",
        "    \"\"\"Custom standard scaler to standardize features.\"\"\"\n",
        "    mean = np.mean(X, axis=0)\n",
        "    std = np.std(X, axis=0)\n",
        "    return (X - mean) / std\n",
        "\n",
        "def custom_label_encode(column):\n",
        "    \"\"\"Custom label encoder to map unique values in a column to integers.\"\"\"\n",
        "    unique_values = column.unique()\n",
        "    encoding_map = {value: index for index, value in enumerate(unique_values)}\n",
        "    return column.map(encoding_map)\n",
        "\n",
        "# Updating the preprocessing function to use the custom standard scaler\n",
        "def preprocess_data_custom(train_data, test_data):\n",
        "    # Combine train and test for consistent preprocessing\n",
        "    test_data['Exited'] = -1  # Assign a placeholder value for Exited in test data\n",
        "    combined_data = pd.concat([train_data, test_data], axis=0)\n",
        "\n",
        "    # Handle missing values (if any) - let's fill with median for simplicity\n",
        "    combined_data.fillna(combined_data.median(numeric_only=True), inplace=True)\n",
        "\n",
        "    # Custom encoding for categorical variables\n",
        "    combined_data['Geography'] = custom_label_encode(combined_data['Geography'])\n",
        "    combined_data['Gender'] = custom_label_encode(combined_data['Gender'])\n",
        "\n",
        "    # Standardize numerical features using custom standard scaler\n",
        "    numerical_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
        "    combined_data[numerical_features] = custom_standard_scaler(combined_data[numerical_features].values)\n",
        "\n",
        "    # Split back the train and test data\n",
        "    train_data = combined_data[combined_data['Exited'] != -1]\n",
        "    test_data = combined_data[combined_data['Exited'] == -1].drop('Exited', axis=1)\n",
        "\n",
        "    # Separate features and target for training data\n",
        "    X = train_data.drop(columns=['CustomerId', 'Surname', 'Exited', 'id'])\n",
        "    y = train_data['Exited']\n",
        "    X_test = test_data.drop(columns=['CustomerId', 'Surname', 'id'])\n",
        "\n",
        "    return X, y, X_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "SIX46GChv741"
      },
      "outputs": [],
      "source": [
        "# Re-implementing metrics and cross-validation from scratch without sklearn\n",
        "\n",
        "def accuracy_score_custom(y_true, y_pred):\n",
        "    \"\"\"Compute accuracy score.\"\"\"\n",
        "    return np.sum(y_true == y_pred) / len(y_true)\n",
        "\n",
        "def precision_score_custom(y_true, y_pred):\n",
        "    \"\"\"Compute precision score.\"\"\"\n",
        "    true_positive = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    predicted_positive = np.sum(y_pred == 1)\n",
        "    return true_positive / predicted_positive if predicted_positive > 0 else 0\n",
        "\n",
        "def recall_score_custom(y_true, y_pred):\n",
        "    \"\"\"Compute recall score.\"\"\"\n",
        "    true_positive = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    actual_positive = np.sum(y_true == 1)\n",
        "    return true_positive / actual_positive if actual_positive > 0 else 0\n",
        "\n",
        "def f1_score_custom(y_true, y_pred):\n",
        "    \"\"\"Compute F1 score.\"\"\"\n",
        "    precision = precision_score_custom(y_true, y_pred)\n",
        "    recall = recall_score_custom(y_true, y_pred)\n",
        "    if precision + recall == 0:\n",
        "        return 0\n",
        "    return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "def roc_auc_score_custom(y_true, y_pred_proba):\n",
        "    \"\"\"Compute ROC AUC score from scratch.\"\"\"\n",
        "    pos_label = 1\n",
        "    neg_label = 0\n",
        "    y_true = np.array(y_true)\n",
        "    sorted_indices = np.argsort(y_pred_proba)[::-1]\n",
        "    y_true_sorted = y_true[sorted_indices]\n",
        "\n",
        "    # Count the number of positive and negative samples\n",
        "    pos_count = np.sum(y_true == pos_label)\n",
        "    neg_count = np.sum(y_true == neg_label)\n",
        "\n",
        "    tpr_list = []\n",
        "    fpr_list = []\n",
        "    tpr = 0\n",
        "    fpr = 0\n",
        "\n",
        "    # Step through the sorted true labels\n",
        "    for i in range(len(y_true_sorted)):\n",
        "        if y_true_sorted[i] == pos_label:\n",
        "            tpr += 1 / pos_count\n",
        "        else:\n",
        "            fpr += 1 / neg_count\n",
        "        tpr_list.append(tpr)\n",
        "        fpr_list.append(fpr)\n",
        "\n",
        "    # Compute the area under the curve using the trapezoidal rule\n",
        "    auc = np.trapz(tpr_list, fpr_list)\n",
        "    return auc\n",
        "\n",
        "def cross_validate_custom(X, y, knn, n_splits=5):\n",
        "    \"\"\"Perform cross-validation from scratch and return performance metrics.\"\"\"\n",
        "    fold_size = len(X) // n_splits\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "    roc_auc_scores = []\n",
        "\n",
        "    for fold in range(n_splits):\n",
        "        # Split the data into training and validation sets\n",
        "        start_val = fold * fold_size\n",
        "        end_val = (fold + 1) * fold_size if fold != n_splits - 1 else len(X)\n",
        "\n",
        "        X_train = np.concatenate([X[:start_val], X[end_val:]], axis=0)\n",
        "        y_train = np.concatenate([y[:start_val], y[end_val:]], axis=0)\n",
        "        X_val = X[start_val:end_val]\n",
        "        y_val = y[start_val:end_val]\n",
        "\n",
        "        # Fit the KNN model on the training data\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on the validation set\n",
        "        y_pred = knn.predict(X_val)\n",
        "        y_pred_proba = knn.predict_proba(X_val)\n",
        "\n",
        "        # Compute and store performance metrics\n",
        "        accuracy_scores.append(accuracy_score_custom(y_val, y_pred))\n",
        "        precision_scores.append(precision_score_custom(y_val, y_pred))\n",
        "        recall_scores.append(recall_score_custom(y_val, y_pred))\n",
        "        f1_scores.append(f1_score_custom(y_val, y_pred))\n",
        "        roc_auc_scores.append(roc_auc_score_custom(y_val, y_pred_proba))\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": np.mean(accuracy_scores),\n",
        "        \"precision\": np.mean(precision_scores),\n",
        "        \"recall\": np.mean(recall_scores),\n",
        "        \"f1_score\": np.mean(f1_scores),\n",
        "        \"roc_auc\": np.mean(roc_auc_scores)\n",
        "    }\n",
        "\n",
        "# Now we can use these custom implementations in cross-validation and evaluation\n",
        "# I will now proceed with training the KNN model using the updated cross-validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "p-QjNWvNv741",
        "outputId": "5554a2df-61b7-40ce-92d8-f22b70d7e141"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./submission.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Making predictions on the test set and generating the final submission file\n",
        "# Initialize KNN with the best parameters\n",
        "# Reload the datasets and apply the updated preprocessing function\n",
        "train_data = pd.read_csv('./train.csv')\n",
        "test_data = pd.read_csv('./test.csv')\n",
        "\n",
        "# Apply the preprocessing function with the custom scaler\n",
        "X, y, X_test = preprocess_data_custom(train_data, test_data)\n",
        "knn_model_final_custom = KNN(k=17, distance_metric='manhattan')\n",
        "\n",
        "# Perform cross-validation with custom implementations\n",
        "cv_results_custom = cross_validate_custom(X.values, y.values.astype(int), knn_model_final_custom, n_splits=5)\n",
        "\n",
        "# Display the cross-validation results\n",
        "cv_results_custom\n",
        "# Fit the final model on the full training dataset\n",
        "knn_model_final_custom.fit(X.values, y.values.astype(int))\n",
        "\n",
        "# Predict probabilities on the test set\n",
        "test_probabilities_custom = knn_model_final_custom.predict_proba(X_test.values)\n",
        "\n",
        "# Load the original test set to get the 'id' column\n",
        "test_data_full = pd.read_csv('./test.csv')\n",
        "\n",
        "# Create the submission DataFrame\n",
        "submission_custom = pd.DataFrame({'id': test_data_full['id'], 'Exited': test_probabilities_custom})\n",
        "\n",
        "# Save the submission to a CSV file\n",
        "submission_file_path_custom = './submission.csv'\n",
        "submission_custom.to_csv(submission_file_path_custom, index=False)\n",
        "\n",
        "submission_file_path_custom  # Output the file path for user to download\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cs506",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}